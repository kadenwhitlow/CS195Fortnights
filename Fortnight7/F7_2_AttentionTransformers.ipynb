{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C192SOmJS6lw"
      },
      "source": [
        "# CS 195: Natural Language Processing\n",
        "## Attention and Transformers\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericmanley/f23-CS195NLP/blob/main/F7_2_AttentionTransformers.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kLBwL4R0ksv"
      },
      "source": [
        "## Reference\n",
        "\n",
        "SLP: Attention, Section 9.8 of Speech and Language Processing by Daniel Jurafsky & James H. Martin https://web.stanford.edu/~jurafsky/slp3/9.pdf\n",
        "\n",
        "SLP: Transformers and Pre-Trained Language Models, Chapter 10 of Speech and Language Processing by Daniel Jurafsky & James H. Martin https://web.stanford.edu/~jurafsky/slp3/10.pdf\n",
        "\n",
        "How do Transformers Work?, Section 1.4 of Hugging Face NLP Course https://huggingface.co/learn/nlp-course/chapter1/4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksxADVpH0ksw"
      },
      "source": [
        "## Reminder: Applied Exploration\n",
        "\n",
        "The applied exploration for this fortnight will be a little different. I want everyone to get some experience fine-tuning an existing model, so this will be the task for the entire fortnight.\n",
        "\n",
        "See the [workshop from last time](https://github.com/ericmanley/F23-CS195NLP/blob/main/F7_1_TransferLearning.ipynb)\n",
        "\n",
        "Fine-tune an existing model with the following requirements\n",
        "* Choose a different starting model - you can use any Hugging Face model, but consider starting with a general one like BART or Llama2.\n",
        "* Choose a different data set - think about something that would be good to include in an application that interests you\n",
        "* Evaluate how well it performed. For sequence-to-sequence model, try going back and using Rouge from Fortnight 1.\n",
        "\n",
        "The Hugging Face NLP course has [examples of fine-tuning for many different tasks](https://huggingface.co/learn/nlp-course/chapter7/1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O02ndSh40ksw"
      },
      "source": [
        "## Preliminary Discussion\n",
        "\n",
        "We often represent things (word embeddings, context, hidden state, etc.) in neural networks as vectors.\n",
        "* interpreted mathematically, vectors have *direction* and *magnitude*\n",
        "\n",
        "Sometimes we want to be able to tell how *similar* two vectors are - for example, two similar words might have similar embedding vectors\n",
        "* similar vectors point in the same direction\n",
        "* we usually *normalize* them so that they're of length 1 but keep the same direction\n",
        "\n",
        "Which of the following two sets of vectors are more similar?\n",
        "\n",
        "(0.383, 0.077, 0.920) and (0.477, 0.191, 0.858)\n",
        "\n",
        "or\n",
        "\n",
        "(0.383, 0.077, 0.920) and  (0.759, 0.569, 0.316)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RoThdL10ksx"
      },
      "source": [
        "## Dot products\n",
        "\n",
        "A **dot product** of two vectors is one way to measure similarity\n",
        "\n",
        "Compute by\n",
        "* multiplying corresponding entries\n",
        "* adding them all together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCZ-LCnM0ksx",
        "outputId": "ac662b33-6c1b-462f-8084-e5c6aee7b81f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.986758"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(0.383*0.477) + (0.077*0.191) + (0.920*0.858)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXFuvQ4l0ktS",
        "outputId": "50868194-0476-4877-86c9-723835c33822"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.62523"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(0.383*0.759) + (0.077*0.569) + (0.920*0.316)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Iv29X30ktT"
      },
      "source": [
        "## Review: The Encoder-Decoder Recurrent Neural Network Architecture\n",
        "\n",
        "<div>\n",
        "    <center>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/encoder-decoder_detail.png?raw=1\">\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "### Discuss:\n",
        "1. What do encoders do? How are they trained?\n",
        "2. What do decoders do? How are they trained.\n",
        "3. What is **c** in this diagram and what is its purpose?\n",
        "\n",
        "\n",
        "image source: SLP Fig. 9.18, https://web.stanford.edu/~jurafsky/slp3/9.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoders: BERT, ALBERT, DistilBERT, ELECTRA, RoBERTa\n",
        "\n",
        "- Usually trained on masked input - model tries to predict the missing word in a sequence\n",
        "\n",
        "Decoders: CTRL, GPT, GPT-2, Transformer XL\n",
        "\n",
        "- Neural language models - usually trying to predict the next word in a sequence\n",
        "- Used to generate text\n",
        "\n",
        "c:\n",
        "\n",
        "- context - the essence of the input sequence or the weights"
      ],
      "metadata": {
        "id": "Cd2BBMOm41KO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rHkejq-0ktZ"
      },
      "source": [
        "## Problem: Bottleneck\n",
        "\n",
        "<div>\n",
        "    <center>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/bottleneck.png?raw=1\" width=700>\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "The final hidden state in the encoder has to contain everything meaningful about the input text\n",
        "* may not represent things from earlier in the input sequence\n",
        "* even if you use LSTM nodes\n",
        "\n",
        "image source: SLP Fig. 9.21, https://web.stanford.edu/~jurafsky/slp3/9.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOm5sRSw0ktZ"
      },
      "source": [
        "## Attention\n",
        "\n",
        "\n",
        "\n",
        "<div>\n",
        "    <center>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/attention.png?raw=1\" width=800>\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "**Idea:** instead of just passing the final hidden encoder state to the decoder, pass a combination of all encoder states\n",
        "* weighted sum: makes sure that the context vector is a fixed size (can be some other more complicated function)\n",
        "* computed again for each decoder state $i$\n",
        "* takes into account decoder state $i-1$ and all encoder states\n",
        "* you can learn *which input words are most important* when generating the next word\n",
        "* even better at retaining long-term information\n",
        "\n",
        "image source: SLP Fig. 9.23, https://web.stanford.edu/~jurafsky/slp3/9.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNC7cQwm0ktZ"
      },
      "source": [
        "## Computing the Attention context vector\n",
        "\n",
        "1. compute the *score* for how relevant each encoder state is to each decoder state\n",
        "    * can be simple - the dot product\n",
        "    * this is a single number that represents how similar the two vectors are\n",
        "    * tells us the relevance of each encoder state to the current step in the decoder\n",
        "2. Normalize these with a softmax to create a vector of weights $\\alpha_{ij}$ - this essentially turns the relevance for each encoder state into probabilities\n",
        "3. Use these normalized relevence scores as weights in a weighted sum - this is our new context vector $$c_i = \\sum_{j} \\alpha_{ij}h^e_j$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrp3YAaO0kta"
      },
      "source": [
        "## Attention is all you need\n",
        "\n",
        "2017: Big breakthrough by researchers at Google - the **Transformer**\n",
        "* You can use attention *without recurrent structures*\n",
        "* recurrent structures: slow training - you have to generate them sequentially\n",
        "* transformers: fast training - you can do it in parallel\n",
        "\n",
        "<div>\n",
        "    <center>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/attention_paper.png?raw=1\">\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "Paper available at https://arxiv.org/abs/1706.03762"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk_7IUrE0kta"
      },
      "source": [
        "## Transformers\n",
        "\n",
        "Transformers include\n",
        "* linear layers\n",
        "* feedforward networks\n",
        "* **self-attention** layers\n",
        "    - directly extract and use information from arbitrarily large contexts\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWXe0eoJ0kta"
      },
      "source": [
        "## A simple self attention layer\n",
        "\n",
        "<div>\n",
        "    <center>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/simple_self_attention.png?raw=1\">\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "* Each output is based on all prior inputs\n",
        "\n",
        "* Similar to recurrent calculation\n",
        "    - compute similarity score of each pair $x_i$ and $x_j$ (can be just dot product)\n",
        "    - normalize with softmax, call it $\\alpha_{ij}$\n",
        "    - generate output as weighted sum of inputs $$y_i = \\sum_{j \\leq i} \\alpha_{ij}x_j$$\n",
        "    \n",
        "* **Note that these can be computed in parallel!**\n",
        "\n",
        "image source: SLP Fig. 10.1, https://web.stanford.edu/~jurafsky/slp3/10.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XpyjF2j0kta"
      },
      "source": [
        "## Fancier Embeddings\n",
        "\n",
        "Transformers generate three new vectors from each word embedding representing different roles a word can play\n",
        "\n",
        "\n",
        "<div>\n",
        "    <center>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/query_key_value.png?raw=1\" width=600>\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "* **Query vector:** used to measure relevance a word should give to other words in a sentence\n",
        "    - current focus of attention\n",
        "* **Key vector:** the vector that a query vector is compared to - how much focus the query word should give to this word\n",
        "    - preceding words being compared to the current focus\n",
        "* **Value vector:** information from the word that should be passed to the other words\n",
        "    - once query and key have been matched, output is mostly the value vector but guided by interaction of query and key\n",
        "    \n",
        "*All of these weights are learned as part of the training process!*\n",
        "\n",
        "image source: SLP Fig. 10.2, https://web.stanford.edu/~jurafsky/slp3/10.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query - find all the words that are important\n",
        "\n",
        "Key - determine how important and how much attention words should be given\n",
        "\n",
        "Value - representation of a word that has the important information about that word"
      ],
      "metadata": {
        "id": "-pczwu6uBLo5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP2uz81f0kta"
      },
      "source": [
        "## Transformer Block\n",
        "\n",
        "<div>\n",
        "    <center>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/transformer_block.png?raw=1\">\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "**Residual connections:** Allow information to skip layers - improves learning, helps with the vanishing gradient\n",
        "\n",
        "**Normalization layers:** Rescale the vectors so that they're all meastured on the same scale (like z-score normalization in statistics) - also includes some learnable parameters called gain and offset for multiplying or adding on to the scaled values\n",
        "\n",
        "image source: SLP Fig. 10.4, https://web.stanford.edu/~jurafsky/slp3/10.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko9B6s0l0kta"
      },
      "source": [
        "## Multi-Headed Attention\n",
        "\n",
        "<div>\n",
        "    <center>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/multiheaded_attention.png?raw=1\">\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "As we have seen, the same word can have many different senses (e.g., a river *bank* vs. a *bank* that is a financial institution)\n",
        "\n",
        "This can happen at each level of abstraction in a neural network language model\n",
        "\n",
        "Each **head** is a self-attention layer capable of handling different relationships between words\n",
        "\n",
        "image source: SLP Fig. 10.5, https://web.stanford.edu/~jurafsky/slp3/10.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m14emCjQ0kta"
      },
      "source": [
        "## Diagram of Encoder-Decoder Transformer\n",
        "\n",
        "Encoder is on left, decoder on right\n",
        "\n",
        "<div>\n",
        "    <center>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/transformer_encoder_decoder.svg?raw=1\">\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "\n",
        "image source: https://huggingface.co/learn/nlp-course/chapter1/4"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
